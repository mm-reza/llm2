{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f972f82d",
   "metadata": {},
   "source": [
    "### Basic working of Google Palm LLM in LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65916f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /opt/miniconda3/envs/llm/lib/python3.12/site-packages/huggingface_hub-0.29.1-py3.8.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: streamlit in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (1.46.1)\n",
      "Requirement already satisfied: altair<6,>=4.0 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.5.0 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<7,>=4.0 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from streamlit) (5.5.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from streamlit) (8.1.8)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from streamlit) (1.26.4)\n",
      "Requirement already satisfied: packaging<26,>=20 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from streamlit) (23.2)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from streamlit) (2.2.3)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from streamlit) (10.4.0)\n",
      "Requirement already satisfied: protobuf<7,>=3.20 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from streamlit) (4.24.4)\n",
      "Requirement already satisfied: pyarrow>=7.0 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from streamlit) (19.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from streamlit) (2.32.3)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from streamlit) (8.5.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from streamlit) (4.12.2)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from streamlit) (3.1.44)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from streamlit) (6.5.1)\n",
      "Requirement already satisfied: jinja2 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from altair<6,>=4.0->streamlit) (3.1.5)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from altair<6,>=4.0->streamlit) (1.27.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from pandas<3,>=1.4.0->streamlit) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from pandas<3,>=1.4.0->streamlit) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit) (2025.6.15)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.23.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2caf1a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /opt/miniconda3/envs/llm/lib/python3.12/site-packages/huggingface_hub-0.29.1-py3.8.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: InstructorEmbedding in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (1.0.1)\n",
      "Requirement already satisfied: torch in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: sentence_transformers in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: google.generativeai in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (0.2.2)\n",
      "Requirement already satisfied: filelock in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: networkx in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from torch) (2025.2.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from sentence_transformers) (4.45.2)\n",
      "Requirement already satisfied: tqdm in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from sentence_transformers) (4.67.1)\n",
      "Requirement already satisfied: torchvision in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from sentence_transformers) (0.17.2)\n",
      "Requirement already satisfied: numpy in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from sentence_transformers) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from sentence_transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from sentence_transformers) (1.15.2)\n",
      "Requirement already satisfied: nltk in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from sentence_transformers) (3.9.1)\n",
      "Requirement already satisfied: sentencepiece in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from sentence_transformers) (0.2.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages/huggingface_hub-0.29.1-py3.8.egg (from sentence_transformers) (0.29.1)\n",
      "Collecting google-ai-generativelanguage==0.3.3 (from google.generativeai)\n",
      "  Downloading google_ai_generativelanguage-0.3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: google-auth in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from google.generativeai) (2.38.0)\n",
      "Requirement already satisfied: google-api-core in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from google.generativeai) (2.24.1)\n",
      "Requirement already satisfied: protobuf in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from google.generativeai) (4.24.4)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from google-ai-generativelanguage==0.3.3->google.generativeai) (1.26.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from google-api-core->google.generativeai) (1.68.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from google-api-core->google.generativeai) (2.32.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from google-auth->google.generativeai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from google-auth->google.generativeai) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from google-auth->google.generativeai) (4.9)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.20.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.4.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: click in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from nltk->sentence_transformers) (8.1.8)\n",
      "Requirement already satisfied: joblib in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from nltk->sentence_transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from torchvision->sentence_transformers) (10.4.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.3.3->google.generativeai) (1.70.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.3.3->google.generativeai) (1.63.0rc1)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth->google.generativeai) (0.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google.generativeai) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google.generativeai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google.generativeai) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google.generativeai) (2025.6.15)\n",
      "Downloading google_ai_generativelanguage-0.3.3-py3-none-any.whl (267 kB)\n",
      "Installing collected packages: google-ai-generativelanguage\n",
      "  Attempting uninstall: google-ai-generativelanguage\n",
      "    Found existing installation: google-ai-generativelanguage 0.6.18\n",
      "    Uninstalling google-ai-generativelanguage-0.6.18:\n",
      "      Successfully uninstalled google-ai-generativelanguage-0.6.18\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-google-genai 2.1.6 requires google-ai-generativelanguage<0.7.0,>=0.6.18, but you have google-ai-generativelanguage 0.3.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed google-ai-generativelanguage-0.3.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install InstructorEmbedding torch sentence_transformers google.generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a34aa70b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/llm/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import GooglePalm\n",
    "import os\n",
    "GOOGLE_API_KEY='AIzaSyBqElgRA9W_7l8b-8LWV6LYymS0NB_7Iv8'\n",
    "# \"AIzaSyBIUqYzxaECWkizdEUz09oMGzwESzoVpic\"\n",
    "llm = GooglePalm(google_api_key=os.environ[\"GOOGLE_API_KEY\"], temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afe82314",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'google.generativeai' has no attribute 'generate_text'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mllm\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtoday\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:189\u001b[39m, in \u001b[36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    187\u001b[39m     warned = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    188\u001b[39m     emit_warning()\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.12/site-packages/langchain_core/language_models/llms.py:1317\u001b[39m, in \u001b[36mBaseLLM.__call__\u001b[39m\u001b[34m(self, prompt, stop, callbacks, tags, metadata, **kwargs)\u001b[39m\n\u001b[32m   1310\u001b[39m     msg = (\n\u001b[32m   1311\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mArgument `prompt` is expected to be a string. Instead found \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1312\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(prompt)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. If you want to run the LLM on multiple prompts, use \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1313\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m`generate` instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1314\u001b[39m     )\n\u001b[32m   1315\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)  \u001b[38;5;66;03m# noqa: TRY004\u001b[39;00m\n\u001b[32m   1316\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m-> \u001b[39m\u001b[32m1317\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1318\u001b[39m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1319\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1320\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1321\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1322\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1323\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1324\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1325\u001b[39m     .generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m]\n\u001b[32m   1326\u001b[39m     .text\n\u001b[32m   1327\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.12/site-packages/langchain_core/language_models/llms.py:973\u001b[39m, in \u001b[36mBaseLLM.generate\u001b[39m\u001b[34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    958\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m    959\u001b[39m     run_managers = [\n\u001b[32m    960\u001b[39m         callback_manager.on_llm_start(\n\u001b[32m    961\u001b[39m             \u001b[38;5;28mself\u001b[39m._serialized,\n\u001b[32m   (...)\u001b[39m\u001b[32m    971\u001b[39m         )\n\u001b[32m    972\u001b[39m     ]\n\u001b[32m--> \u001b[39m\u001b[32m973\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    978\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    979\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) > \u001b[32m0\u001b[39m:\n\u001b[32m    981\u001b[39m     run_managers = [\n\u001b[32m    982\u001b[39m         callback_managers[idx].on_llm_start(\n\u001b[32m    983\u001b[39m             \u001b[38;5;28mself\u001b[39m._serialized,\n\u001b[32m   (...)\u001b[39m\u001b[32m    990\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m missing_prompt_idxs\n\u001b[32m    991\u001b[39m     ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.12/site-packages/langchain_core/language_models/llms.py:792\u001b[39m, in \u001b[36mBaseLLM._generate_helper\u001b[39m\u001b[34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[39m\n\u001b[32m    781\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_generate_helper\u001b[39m(\n\u001b[32m    782\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    783\u001b[39m     prompts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m    788\u001b[39m     **kwargs: Any,\n\u001b[32m    789\u001b[39m ) -> LLMResult:\n\u001b[32m    790\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    791\u001b[39m         output = (\n\u001b[32m--> \u001b[39m\u001b[32m792\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m                \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[32m    796\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    799\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m    800\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._generate(prompts, stop=stop)\n\u001b[32m    801\u001b[39m         )\n\u001b[32m    802\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    803\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.12/site-packages/langchain_community/llms/google_palm.py:180\u001b[39m, in \u001b[36mGooglePalm._generate\u001b[39m\u001b[34m(self, prompts, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    178\u001b[39m     generations.append([Generation(text=c) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m candidates])\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m     res = \u001b[43mcompletion_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_gemini\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    189\u001b[39m     prompt_generations = []\n\u001b[32m    190\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m candidate \u001b[38;5;129;01min\u001b[39;00m res.candidates:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.12/site-packages/langchain_community/llms/google_palm.py:40\u001b[39m, in \u001b[36mcompletion_with_retry\u001b[39m\u001b[34m(llm, prompt, is_gemini, stream, run_manager, **kwargs)\u001b[39m\n\u001b[32m     35\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m llm.client.generate_content(\n\u001b[32m     36\u001b[39m             contents=prompt, stream=stream, generation_config=generation_config\n\u001b[32m     37\u001b[39m         )\n\u001b[32m     38\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m llm.client.generate_text(prompt=prompt, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_completion_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_gemini\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_gemini\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.12/site-packages/tenacity/__init__.py:336\u001b[39m, in \u001b[36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    334\u001b[39m copy = \u001b[38;5;28mself\u001b[39m.copy()\n\u001b[32m    335\u001b[39m wrapped_f.statistics = copy.statistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m336\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.12/site-packages/tenacity/__init__.py:475\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    473\u001b[39m retry_state = RetryCallState(retry_object=\u001b[38;5;28mself\u001b[39m, fn=fn, args=args, kwargs=kwargs)\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    476\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    477\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.12/site-packages/tenacity/__init__.py:376\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    374\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m376\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.12/site-packages/tenacity/__init__.py:398\u001b[39m, in \u001b[36mBaseRetrying._post_retry_check_actions.<locals>.<lambda>\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    396\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_post_retry_check_actions\u001b[39m(\u001b[38;5;28mself\u001b[39m, retry_state: \u001b[33m\"\u001b[39m\u001b[33mRetryCallState\u001b[39m\u001b[33m\"\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    397\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.iter_state.is_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.retry_run_result):\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m         \u001b[38;5;28mself\u001b[39m._add_action_func(\u001b[38;5;28;01mlambda\u001b[39;00m rs: \u001b[43mrs\u001b[49m\u001b[43m.\u001b[49m\u001b[43moutcome\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    399\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    401\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.after \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.12/concurrent/futures/_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.12/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.12/site-packages/tenacity/__init__.py:478\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    477\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m478\u001b[39m         result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    479\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[32m    480\u001b[39m         retry_state.set_exception(sys.exc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.12/site-packages/langchain_community/llms/google_palm.py:38\u001b[39m, in \u001b[36mcompletion_with_retry.<locals>._completion_with_retry\u001b[39m\u001b[34m(prompt, is_gemini, stream, **kwargs)\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_gemini:\n\u001b[32m     35\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m llm.client.generate_content(\n\u001b[32m     36\u001b[39m         contents=prompt, stream=stream, generation_config=generation_config\n\u001b[32m     37\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_text\u001b[49m(prompt=prompt, **kwargs)\n",
      "\u001b[31mAttributeError\u001b[39m: module 'google.generativeai' has no attribute 'generate_text'"
     ]
    }
   ],
   "source": [
    "llm('today')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a6f734",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58499072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /opt/miniconda3/envs/llm/lib/python3.12/site-packages/huggingface_hub-0.29.1-py3.8.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: langchain-google-genai in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (2.1.6)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from langchain-google-genai) (1.2.0)\n",
      "Requirement already satisfied: google-ai-generativelanguage<0.7.0,>=0.6.18 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from langchain-google-genai) (0.6.18)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.66 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from langchain-google-genai) (0.3.68)\n",
      "Requirement already satisfied: pydantic<3,>=2 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from langchain-google-genai) (2.10.6)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.24.1)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.38.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.26.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (4.24.4)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.66->langchain-google-genai) (0.4.4)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.66->langchain-google-genai) (8.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.66->langchain-google-genai) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.66->langchain-google-genai) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.66->langchain-google-genai) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.66->langchain-google-genai) (4.12.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from pydantic<3,>=2->langchain-google-genai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from pydantic<3,>=2->langchain-google-genai) (2.27.2)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.68.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.32.3)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.70.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.63.0rc1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (4.9)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.66->langchain-google-genai) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.66->langchain-google-genai) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.66->langchain-google-genai) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.66->langchain-google-genai) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.66->langchain-google-genai) (0.23.0)\n",
      "Requirement already satisfied: anyio in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.66->langchain-google-genai) (4.8.0)\n",
      "Requirement already satisfied: certifi in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.66->langchain-google-genai) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.66->langchain-google-genai) (1.0.7)\n",
      "Requirement already satisfied: idna in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.66->langchain-google-genai) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.66->langchain-google-genai) (0.14.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.66->langchain-google-genai) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7d8e4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /opt/miniconda3/envs/llm/lib/python3.12/site-packages/huggingface_hub-0.29.1-py3.8.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: langchain-google-genai in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (2.1.6)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from langchain-google-genai) (1.2.0)\n",
      "Collecting google-ai-generativelanguage<0.7.0,>=0.6.18 (from langchain-google-genai)\n",
      "  Using cached google_ai_generativelanguage-0.6.18-py3-none-any.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.66 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from langchain-google-genai) (0.3.68)\n",
      "Requirement already satisfied: pydantic<3,>=2 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from langchain-google-genai) (2.10.6)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.24.1)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.38.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.26.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (4.24.4)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.66->langchain-google-genai) (0.4.4)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.66->langchain-google-genai) (8.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.66->langchain-google-genai) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.66->langchain-google-genai) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.66->langchain-google-genai) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.66->langchain-google-genai) (4.12.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from pydantic<3,>=2->langchain-google-genai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from pydantic<3,>=2->langchain-google-genai) (2.27.2)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.68.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.32.3)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.70.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.63.0rc1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (4.9)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.66->langchain-google-genai) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.66->langchain-google-genai) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.66->langchain-google-genai) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.66->langchain-google-genai) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.66->langchain-google-genai) (0.23.0)\n",
      "Requirement already satisfied: anyio in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.66->langchain-google-genai) (4.8.0)\n",
      "Requirement already satisfied: certifi in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.66->langchain-google-genai) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.66->langchain-google-genai) (1.0.7)\n",
      "Requirement already satisfied: idna in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.66->langchain-google-genai) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.66->langchain-google-genai) (0.14.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/miniconda3/envs/llm/lib/python3.12/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.66->langchain-google-genai) (1.3.1)\n",
      "Using cached google_ai_generativelanguage-0.6.18-py3-none-any.whl (1.4 MB)\n",
      "Installing collected packages: google-ai-generativelanguage\n",
      "  Attempting uninstall: google-ai-generativelanguage\n",
      "    Found existing installation: google-ai-generativelanguage 0.3.3\n",
      "    Uninstalling google-ai-generativelanguage-0.3.3:\n",
      "      Successfully uninstalled google-ai-generativelanguage-0.3.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-generativeai 0.2.2 requires google-ai-generativelanguage==0.3.3, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed google-ai-generativelanguage-0.6.18\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af4eea0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "llm = GoogleGenerativeAI(model=\"gemini-pro\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88f2795d",
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_API_KEY='AIzaSyBqElgRA9W_7l8b-8LWV6LYymS0NB_7Iv8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98fc3d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised NotFound: 404 models/gemini-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods..\n"
     ]
    },
    {
     "ename": "NotFound",
     "evalue": "404 models/gemini-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotFound\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_google_genai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatGoogleGenerativeAI\n\u001b[32m      3\u001b[39m llm = ChatGoogleGenerativeAI(model=\u001b[33m\"\u001b[39m\u001b[33mgemini-pro\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m response = \u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSing a ballad of LangChain.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(response.content)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.12/site-packages/langchain_google_genai/chat_models.py:1326\u001b[39m, in \u001b[36mChatGoogleGenerativeAI.invoke\u001b[39m\u001b[34m(self, input, config, code_execution, stop, **kwargs)\u001b[39m\n\u001b[32m   1321\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1322\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1323\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mTools are already defined.\u001b[39m\u001b[33m\"\u001b[39m \u001b[33m\"\u001b[39m\u001b[33mcode_execution tool can\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt be defined\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1324\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1326\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:378\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    366\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    367\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    368\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    373\u001b[39m     **kwargs: Any,\n\u001b[32m    374\u001b[39m ) -> BaseMessage:\n\u001b[32m    375\u001b[39m     config = ensure_config(config)\n\u001b[32m    376\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    377\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    388\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:963\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    954\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    955\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    956\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    960\u001b[39m     **kwargs: Any,\n\u001b[32m    961\u001b[39m ) -> LLMResult:\n\u001b[32m    962\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m963\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:782\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    779\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    780\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    781\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m782\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    783\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    784\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    785\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    786\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    787\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    788\u001b[39m         )\n\u001b[32m    789\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    790\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:1028\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1026\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1027\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1028\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1029\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1030\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1031\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1032\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.12/site-packages/langchain_google_genai/chat_models.py:1433\u001b[39m, in \u001b[36mChatGoogleGenerativeAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[39m\n\u001b[32m   1406\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_generate\u001b[39m(\n\u001b[32m   1407\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1408\u001b[39m     messages: List[BaseMessage],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1419\u001b[39m     **kwargs: Any,\n\u001b[32m   1420\u001b[39m ) -> ChatResult:\n\u001b[32m   1421\u001b[39m     request = \u001b[38;5;28mself\u001b[39m._prepare_request(\n\u001b[32m   1422\u001b[39m         messages,\n\u001b[32m   1423\u001b[39m         stop=stop,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1431\u001b[39m         **kwargs,\n\u001b[32m   1432\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1433\u001b[39m     response: GenerateContentResponse = \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1434\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1435\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1436\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_method\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1437\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdefault_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1438\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1439\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _response_to_result(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.12/site-packages/langchain_google_genai/chat_models.py:231\u001b[39m, in \u001b[36m_chat_with_retry\u001b[39m\u001b[34m(generation_method, **kwargs)\u001b[39m\n\u001b[32m    222\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    224\u001b[39m params = (\n\u001b[32m    225\u001b[39m     {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m _allowed_params_prediction_service}\n\u001b[32m    226\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (request := kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m   (...)\u001b[39m\u001b[32m    229\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m kwargs\n\u001b[32m    230\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m231\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.12/site-packages/tenacity/__init__.py:336\u001b[39m, in \u001b[36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    334\u001b[39m copy = \u001b[38;5;28mself\u001b[39m.copy()\n\u001b[32m    335\u001b[39m wrapped_f.statistics = copy.statistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m336\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.12/site-packages/tenacity/__init__.py:475\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    473\u001b[39m retry_state = RetryCallState(retry_object=\u001b[38;5;28mself\u001b[39m, fn=fn, args=args, kwargs=kwargs)\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    476\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    477\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.12/site-packages/tenacity/__init__.py:376\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    374\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m376\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.12/site-packages/tenacity/__init__.py:418\u001b[39m, in \u001b[36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    416\u001b[39m retry_exc = \u001b[38;5;28mself\u001b[39m.retry_error_cls(fut)\n\u001b[32m    417\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.reraise:\n\u001b[32m--> \u001b[39m\u001b[32m418\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfut\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexception\u001b[39;00m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.12/site-packages/tenacity/__init__.py:185\u001b[39m, in \u001b[36mRetryError.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    183\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> t.NoReturn:\n\u001b[32m    184\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.last_attempt.failed:\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlast_attempt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    186\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.12/concurrent/futures/_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.12/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.12/site-packages/tenacity/__init__.py:478\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    477\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m478\u001b[39m         result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    479\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[32m    480\u001b[39m         retry_state.set_exception(sys.exc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.12/site-packages/langchain_google_genai/chat_models.py:222\u001b[39m, in \u001b[36m_chat_with_retry.<locals>._chat_with_retry\u001b[39m\u001b[34m(**kwargs)\u001b[39m\n\u001b[32m    218\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ChatGoogleGenerativeAIError(\n\u001b[32m    219\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid argument provided to Gemini: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    220\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    221\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m222\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.12/site-packages/langchain_google_genai/chat_models.py:206\u001b[39m, in \u001b[36m_chat_with_retry.<locals>._chat_with_retry\u001b[39m\u001b[34m(**kwargs)\u001b[39m\n\u001b[32m    203\u001b[39m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_chat_with_retry\u001b[39m(**kwargs: Any) -> Any:\n\u001b[32m    205\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgeneration_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    207\u001b[39m     \u001b[38;5;66;03m# Do not retry for these errors.\u001b[39;00m\n\u001b[32m    208\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m google.api_core.exceptions.FailedPrecondition \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:868\u001b[39m, in \u001b[36mGenerativeServiceClient.generate_content\u001b[39m\u001b[34m(self, request, model, contents, retry, timeout, metadata)\u001b[39m\n\u001b[32m    865\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_universe_domain()\n\u001b[32m    867\u001b[39m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m868\u001b[39m response = \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    869\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    870\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    871\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[32m    876\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py:131\u001b[39m, in \u001b[36m_GapicCallable.__call__\u001b[39m\u001b[34m(self, timeout, retry, compression, *args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    129\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mcompression\u001b[39m\u001b[33m\"\u001b[39m] = compression\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py:293\u001b[39m, in \u001b[36mRetry.__call__.<locals>.retry_wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    289\u001b[39m target = functools.partial(func, *args, **kwargs)\n\u001b[32m    290\u001b[39m sleep_generator = exponential_sleep_generator(\n\u001b[32m    291\u001b[39m     \u001b[38;5;28mself\u001b[39m._initial, \u001b[38;5;28mself\u001b[39m._maximum, multiplier=\u001b[38;5;28mself\u001b[39m._multiplier\n\u001b[32m    292\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py:153\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    149\u001b[39m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[32m    150\u001b[39m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    152\u001b[39m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m     \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m        \u001b[49m\u001b[43msleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[32m    164\u001b[39m     time.sleep(sleep)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.12/site-packages/google/api_core/retry/retry_base.py:212\u001b[39m, in \u001b[36m_retry_error_helper\u001b[39m\u001b[34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[39m\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[32m    207\u001b[39m     final_exc, source_exc = exc_factory_fn(\n\u001b[32m    208\u001b[39m         error_list,\n\u001b[32m    209\u001b[39m         RetryFailureReason.NON_RETRYABLE_ERROR,\n\u001b[32m    210\u001b[39m         original_timeout,\n\u001b[32m    211\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msource_exc\u001b[39;00m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    214\u001b[39m     on_error_fn(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py:144\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m         result = \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    145\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m inspect.isawaitable(result):\n\u001b[32m    146\u001b[39m             warnings.warn(_ASYNC_RETRY_WARNING)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.12/site-packages/google/api_core/timeout.py:130\u001b[39m, in \u001b[36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    126\u001b[39m         remaining_timeout = \u001b[38;5;28mself\u001b[39m._timeout\n\u001b[32m    128\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m] = remaining_timeout\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.12/site-packages/google/api_core/grpc_helpers.py:78\u001b[39m, in \u001b[36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(*args, **kwargs)\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m grpc.RpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions.from_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[31mNotFound\u001b[39m: 404 models/gemini-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods."
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\")\n",
    "response = llm.invoke(\"Sing a ballad of LangChain.\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3bd94ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05636945366859436, 0.004828543867915869, -0.07625909894704819, -0.023642510175704956, 0.053293220698833466, 0.016581406816840172, 0.009121587499976158, -0.024947555735707283, 0.007700750138610601, 0.03362567722797394, -0.020514147356152534, 0.027804017066955566, -0.030172377824783325, 0.00731416093185544, -0.010856682434678078, -0.03597740828990936, 0.021513955667614937, 0.01633325032889843, 0.021469051018357277, 0.0036604278720915318, 0.0011925423750653863, 0.008980481885373592, -0.018995895981788635, -0.009184079244732857, 0.04040118679404259, -0.0037098026368767023, 0.01273257378488779, -0.04851049557328224, -0.016665350645780563, -0.0008384200045838952, -0.03567149490118027, 0.0029531021136790514, -0.030754543840885162, 0.029062796384096146, 0.029468625783920288, -0.06395961344242096, 0.012810896150767803, 0.005382996518164873, -0.0006807728204876184, -0.016550464555621147, 0.0203824695199728, -0.06957278400659561, -0.03829100355505943, 0.013464502990245819, 0.008654627948999405, 0.01564653217792511, -0.02847709134221077, 0.02478848211467266, 0.014004271477460861, -0.06210032477974892, 0.043544553220272064, 0.02308098040521145, 0.07201849669218063, -0.02729986235499382, 0.0051528532058000565, -0.018753286451101303, 0.07514780759811401, 0.0012924663024023175, -0.03838604688644409, 0.03254418820142746, 0.0070606111548841, 0.026144281029701233, 0.03363370895385742, 0.020686212927103043, -0.021631943061947823, -0.06628305464982986, -0.05425587296485901, 0.025455614551901817, 0.029365338385105133, -0.008641820400953293, -0.012392623350024223, -0.0374428927898407, 0.027592020109295845, -0.002535817213356495, 0.021539265289902687, -0.12243212014436722, -0.00489209545776248, 0.03237127140164375, 0.010215661488473415, -0.028095100075006485, 0.010700276121497154, -0.05027519538998604, -0.07446381449699402, -0.020474886521697044, -0.08344609290361404, 0.007217992562800646, -0.03073924407362938, -0.008320853114128113, 0.007250982336699963, 0.04450220987200737, -0.02370179072022438, -0.018427301198244095, 0.07605741173028946, -0.04431670531630516, -0.00626528961583972, 0.0738566517829895, -0.04392317309975624, -0.040811456739902496, 0.03160325065255165, -0.02560945600271225, 0.02219027280807495, -0.040485553443431854, -0.05056464299559593, 0.013237099163234234, 0.04734400287270546, 0.012719797901809216, 0.014087126590311527, 0.03638910502195358, 0.010662042535841465, 0.03189774975180626, -0.07149019092321396, 0.025721710175275803, -0.005157558713108301, 0.00966675952076912, 0.02903515100479126, -0.022939123213291168, -0.007333025801926851, 0.08429435640573502, 0.034341033548116684, 0.059226635843515396, 0.02778458595275879, -0.010789490304887295, 0.06956002116203308, -0.04783248156309128, 0.013920245692133904, -0.010476279072463512, -0.007181677035987377, 0.053221140056848526, 0.005050948355346918, -0.005711446050554514, -0.016810782253742218, -0.05283616483211517, -0.014297638088464737, 0.01818002760410309, 0.05089668929576874, 0.06803375482559204, 0.043241236358881, -0.041396841406822205, 0.014972816221415997, -0.019742725417017937, 0.012530568055808544, 0.029355386272072792, 0.001715998281724751, 0.017853321507573128, -0.02042074128985405, 0.059983737766742706, -0.07217538356781006, -0.00783490389585495, 0.05029449239373207, -0.03663967549800873, -0.015295502729713917, 0.004349385853856802, -0.07051243633031845, -0.023989088833332062, 0.06699911504983902, -0.017289645969867706, -0.035866331309080124, 0.02602565474808216, 0.03032456338405609, 0.013003681786358356, 0.008442910388112068, -0.02114628627896309, 0.04023958370089531, 0.03885077312588692, -0.0056920042261481285, -0.03875816985964775, -0.031216245144605637, -0.008275208063423634, -0.020273445174098015, 0.012085480615496635, -0.01991255022585392, 0.019620686769485474, -0.03321053832769394, -0.03751638904213905, -0.0020191201474517584, -0.05271347612142563, 0.04567674919962883, -0.007474944461137056, -0.052749693393707275, -0.014606055803596973, 0.01766851916909218, -0.022748135030269623, 0.02236156351864338, 0.05372069776058197, 0.002864919835701585, -0.03858691826462746, 0.07370339334011078, -0.010301094502210617, -0.005410545505583286, 0.034386228770017624, -0.0010664748260751367, 0.008932013995945454, -0.03999228775501251, -0.04114192724227905, -0.028519095852971077, 0.05251157283782959, 0.00048816774506121874, 0.023079294711351395, 0.026498615741729736, -0.03665889799594879, 0.016592353582382202, 0.080140121281147, -0.007510250434279442, -0.018839813768863678, 0.03606723994016647, -0.030028555542230606, 0.07566475868225098, -0.04840242490172386, -0.035173315554857254, 0.03204871341586113, -0.02937447838485241, 0.019700493663549423, -0.0005322105716913939, -0.010233811102807522, 0.03471922129392624, 0.003960388246923685, 0.0008809792343527079, 0.021223191171884537, 0.005834612995386124, -0.0336538702249527, -0.0260534156113863, -0.0038182223215699196, -0.01913674920797348, 0.008364519104361534, 0.008226758800446987, 0.054127562791109085, -0.014415016397833824, -0.013857439160346985, 0.014251699671149254, -0.04387762397527695, -0.01859879493713379, 0.08226782828569412, 0.0032269535586237907, 0.0019513607257977128, 0.06127452105283737, -0.02603769116103649, -0.012192576192319393, 0.020484386011958122, 0.0190605279058218, 0.037449613213539124, -0.057265713810920715, 0.02270231954753399, 0.031173648312687874, 0.052084363996982574, -0.08310598880052567, -0.03800184652209282, -0.0404159277677536, 0.03648409992456436, -0.006606860086321831, 0.04341910779476166, 0.016925953328609467, -0.045592933893203735, -0.010111348703503609, -0.001981977839022875, -0.09942474216222763, 0.026244811713695526, -0.02390405908226967, 0.022502966225147247, -0.05113814026117325, 0.005194400902837515, 0.05945229530334473, -0.0024987845681607723, 0.0160095002502203, -0.010290667414665222, -0.01407106313854456, -0.03156430646777153, 0.04224595054984093, -0.07097591459751129, 0.023530304431915283, 0.014204625971615314, 0.012227854691445827, -0.02216043882071972, 0.052640754729509354, 0.006286711897701025, 0.004463370889425278, 0.008531598374247551, -0.008572959341108799, 0.0681648924946785, 0.02778700180351734, -0.04564044997096062, 0.019912611693143845, 0.023864952847361565, 0.0522477850317955, -0.026659611612558365, 0.021596794947981834, 0.0004153563058935106, -0.048671238124370575, -0.025484446436166763, 0.02655087783932686, -0.05079411715269089, -0.023884568363428116, -0.034760378301143646, 0.036471202969551086, -0.026929112151265144, -0.03230954334139824, 0.0023217452690005302, 0.009241048246622086, 0.021568162366747856, 0.012835799716413021, -0.05120997130870819, -0.012821001932024956, -0.0858791172504425, 0.017223745584487915, -0.08682159334421158, -0.027353210374712944, 0.011049172841012478, -0.011938691139221191, -0.046457916498184204, 0.04167339205741882, 0.03792933374643326, -0.013468337245285511, 0.01831739954650402, -0.03511185199022293, 0.012397583574056625, 0.05633394420146942, 0.03457793965935707, -0.019246036186814308, 0.030794797465205193, -0.007722634356468916, 0.04932454600930214, 0.015289339236915112, 0.07957729697227478, 0.0129698496311903, -0.004404550418257713, -0.027048278599977493, 0.05032765120267868, 0.02333010546863079, 0.006355590187013149, -0.01607489585876465, 0.014015506021678448, -0.02054409869015217, 0.023093752562999725, -0.05494595319032669, -0.010435775853693485, -0.01076173409819603, 0.03190743178129196, -0.07785457372665405, 0.023190218955278397, -0.04206307604908943, -0.029188549146056175, -0.03299982473254204, 0.008548656478524208, -0.0345478318631649, -0.04776538908481598, 0.010628699325025082, -0.0005401367088779807, -0.04642690718173981, 0.04305926337838173, 0.06537464261054993, 0.052412934601306915, 0.004538277629762888, 0.08511374890804291, -0.035438720136880875, 0.04796924069523811, -0.004041347187012434, -0.03986453264951706, 0.04026138409972191, -0.02916848659515381, 0.023058442398905754, -0.026070639491081238, 0.02101605385541916, 0.03011399880051613, -0.01906803995370865, -0.03787577524781227, -0.022637810558080673, 0.007077089510858059, -0.021340856328606606, -0.008361829444766045, -0.007306783460080624, 0.06122053787112236, 0.013647099025547504, -0.03049836866557598, 0.027498960494995117, -0.06268319487571716, 0.02167697623372078, 0.018717488273978233, -0.04166415333747864, -0.023699123412370682, 0.03170061483979225, 0.01589469611644745, 0.0001417712919646874, 0.005431420635432005, 0.03947598487138748, -0.003331555053591728, 0.02427142858505249, -0.018294284120202065, 0.0400126688182354, 0.025203902274370193, -0.037043262273073196, 0.024100320413708687, -0.0581982247531414, 0.025797560811042786, 0.08739884197711945, 0.015187573619186878, 0.008344892412424088, -0.0367007851600647, -0.016925808042287827, -0.06347272545099258, 0.018465222790837288, 0.03161727637052536, -0.02078906260430813, -0.056156326085329056, -0.031061790883541107, 0.01745765097439289, -0.0665895938873291, 0.015336154028773308, 0.018071526661515236, -0.004009938798844814, -0.04897969216108322, -0.03043396584689617, 0.026167334988713264, -0.017021184787154198, 0.011838163249194622, -0.06414105743169785, -0.05532993748784065, -0.053099460899829865, 0.05305773392319679, -0.018815847113728523, -0.04396190866827965, 0.0248753409832716, -0.010733095929026604, -0.007106495089828968, 0.002068021334707737, -0.012915573082864285, -0.06904703378677368, -0.01703445427119732, 0.041992779821157455, 0.03870498389005661, -0.004457551054656506, 0.0007889284170232713, 0.02404063567519188, 0.014460735023021698, -0.01994333602488041, -0.020555203780531883, -0.016410158947110176, -0.06371241062879562, 0.0029578895773738623, 0.05001068487763405, -0.03901417925953865, 0.00855325534939766, 0.029842214658856392, -0.03907354921102524, 0.03338901326060295, -0.02872159332036972, -0.001542482408694923, -0.02283342368900776, -0.038416191935539246, -0.026120387017726898, 0.006418832112103701, -0.09011159837245941, 0.053424883633852005, -0.10181961953639984, -0.01611276902258396, -0.07066129893064499, -0.06482957303524017, -0.02985665202140808, 0.01937081478536129, 0.06434167921543121, -0.02743946574628353, 0.016588876023888588, -0.007347563747316599, -0.0025589584838598967, -0.007789440918713808, -0.08874732255935669, 0.03064696118235588, -0.024463806301355362, 0.006090232636779547, -0.0007820373284630477, 0.03217306733131409, 0.04224523529410362, 0.011890253983438015, -0.008709283545613289, -0.00127744534984231, -0.020960113033652306, -0.020031031221151352, -0.004788388963788748, -0.08428129553794861, 0.045739173889160156, -0.04102329537272453, -0.0028214571066200733, 0.01424351055175066, 0.028184248134493828, -0.006103315856307745, 0.024074532091617584, -0.018548406660556793, 0.020784107968211174, 0.018155833706259727, -0.013258266262710094, -0.04521004855632782, 0.07055804878473282, 0.03928298503160477, -0.01844654232263565, -0.01435852237045765, -0.016621427610516548, -0.026748953387141228, 0.0085279680788517, -0.017711646854877472, 0.057374484837055206, 0.046263329684734344, 0.042461857199668884, -0.02029556781053543, -0.024982327595353127, -0.004995816852897406, -0.013221184723079205, 0.08702635020017624, -0.08971016854047775, -0.015409469604492188, 0.047343041747808456, 0.019486267119646072, -0.006939553655683994, -0.0021789141464978456, 0.02915678732097149, -0.022890496999025345, 0.0018507677596062422, 0.05158600956201553, -0.044621895998716354, 0.017932292073965073, -0.016078371554613113, 0.009767227806150913, 0.0026225000619888306, 0.0347183421254158, -0.014531844295561314, -0.07787556201219559, -0.025973504409193993, -0.00841800682246685, -0.04889776557683945, -0.022412318736314774, 0.010902841575443745, -0.037452828139066696, 0.023944320157170296, -0.041260674595832825, 0.08507899194955826, -0.06673672050237656, -0.014124308712780476, 0.04650280624628067, 0.008055750280618668, 0.03937181457877159, 0.03176674246788025, -0.030921993777155876, -0.022409070283174515, 0.06568226218223572, -0.008782490156590939, 0.05221674218773842, 0.01587512716650963, -0.04523419216275215, 0.02133917436003685, 0.013617734424769878, -0.07723475992679596, -0.007028752472251654, -0.008291109465062618, -0.010585043579339981, 0.032828833907842636, 0.039128709584474564, -0.0028128791600465775, 0.01833406090736389, -0.0051963129080832005, 7.125632691895589e-05, 0.006818349007517099, 0.05024542286992073, 0.004113354254513979, 0.03830600529909134, 0.013369844295084476, 0.01321823988109827, 0.01744753308594227, 0.06657431274652481, 0.012502900324761868, -0.019218120723962784, -0.019317548722028732, 0.06356967985630035, -0.014843162149190903, -0.03137650340795517, 0.0016897798050194979, 0.031633585691452026, -0.021971873939037323, 0.05388045683503151, -0.03495284169912338, -0.06351150572299957, -0.00821756012737751, -0.019496621564030647, 0.008387369103729725, 0.06764164566993713, -0.017139676958322525, -0.017752468585968018, 0.08030395209789276, -0.03031201846897602, 0.00874941237270832, 0.0634661540389061, 0.05505825951695442, 0.04494251683354378, 0.01300348062068224, -0.03888968750834465, 0.013286176137626171, -0.00915646180510521, 0.002648850902915001, -0.019247569143772125, 0.006420967169106007, 0.02954917773604393, -0.019010884687304497, -0.001946320990100503, -0.014344383962452412, 0.02189401537179947, -0.033752020448446274, 0.0452459380030632, -0.052030015736818314, 0.035490088164806366, 0.030112119391560555, -0.023525424301624298, 0.0045160879381000996, 0.031008079648017883, 0.09886401146650314, 0.0030404177960008383, -0.03980492427945137, 0.0024424807634204626, -0.026769893243908882, -0.021981073543429375, -0.051601480692625046, 0.08637349307537079, -0.0002653819974511862, -0.018650945276021957, -0.0321502648293972, -0.01497470960021019, 0.020033366978168488, 0.01251797191798687, -0.0027309164870530367, 0.019745081663131714, -0.001019854098558426, -0.04214176535606384, -0.0100936871021986, 0.052782896906137466, 0.044438112527132034, 0.05431897193193436, 0.05858325958251953, -0.019253704696893692, 0.02505052462220192, -0.025664329528808594, 0.004475576803088188, 0.0003869613283313811, 0.02976067177951336, 0.06263154745101929, -0.0026315301656723022, -0.07570504397153854, 0.006072328891605139, 0.008393241092562675, -0.0013197084190323949, -0.02040041610598564, 0.06780515611171722, 0.025253191590309143, -0.09603612869977951, -0.055925898253917694, -0.0054472931660711765, -0.0065510631538927555, -0.005703155416995287, 0.008759137243032455, -0.013894314877688885, 0.011539607308804989, 0.04745457321405411, -0.0208282470703125, -0.04824968799948692, 0.022594023495912552, -0.02474605105817318, -0.03937756270170212, -0.008046013303101063, -0.02714853174984455, 0.0026987011078745127, 0.038012225180864334, -0.0371052548289299, -0.05023142322897911, -0.0960560217499733, -0.014564746990799904, 0.04370364919304848, -0.06522854417562485, 0.030908245593309402, 0.048514530062675476, -0.006925167981535196, 0.03740182891488075, 0.017971506342291832, 0.0038346729706972837, 0.02959926426410675, 0.009997268207371235, 0.023677010089159012, 0.02858995459973812, -0.011191381141543388, -0.03529944643378258, 0.02688213810324669, 0.0030256619211286306, 0.036998450756073, 0.02091951295733452, -0.018577445298433304, -0.04356440529227257, -0.025784114375710487, 0.011890994384884834, -0.013990131206810474, 0.01578342914581299, 0.04595538228750229, 0.025318512693047523, 0.045220427215099335, -0.0038395323790609837, -0.008295266889035702, 0.020707493647933006, 0.05026238411664963, -0.02591370791196823, -0.040177322924137115, -0.013695765286684036, 0.008210055530071259, 0.037756577134132385, 0.005459380801767111, 0.025457827374339104, 0.02819165773689747, 0.013911974616348743, 0.05752992257475853, -0.00526418024674058, -0.04423798620700836, -0.011270388029515743, 0.042830921709537506, 0.016026612371206284, -0.044442351907491684, 0.007711983285844326, 0.04563549533486366, -0.02208334393799305, 0.05792493000626564, 0.046266015619039536, 0.04655207321047783, 0.03591116890311241, -0.017184218391776085, -0.057060085237026215, 0.06882394105195999, -0.0447416715323925, -0.014801731333136559, -0.037251126021146774, -0.037586722522974014, 0.0972137451171875, -0.03139397129416466, 0.012604620307683945, 0.011357015930116177, -0.017643706873059273, 0.07346345484256744, 0.022119272500276566, 0.02242157980799675, -0.002407303312793374, -0.0743367075920105, -0.04303254932165146, 0.009829450398683548, 0.007506531197577715, 0.05625610053539276, 0.03358282521367073, -0.005389992613345385, 0.01585165597498417, -0.0040757134556770325, 0.01343193557113409, -0.05867788568139076, -0.04273899272084236, -0.005954529624432325, -0.04020451381802559, 0.0641026496887207, 0.03829839453101158, 0.00021148176165297627, -0.007055447902530432, 0.0006223602104000747, -0.007670338731259108, 0.0037433651741594076, -0.048108432441949844, -0.025054939091205597, 0.00540347583591938, -0.007658781483769417, 0.03187130019068718, 0.006022395100444555, -0.029771385714411736, 0.004944094456732273]\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "vector = embeddings.embed_query(\"hello, world!\")\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b610123",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised NotFound: 404 models/gemini-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods..\n"
     ]
    },
    {
     "ename": "NotFound",
     "evalue": "404 models/gemini-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotFound\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m response = \u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSing a ballad of LangChain.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.12/site-packages/langchain_core/language_models/llms.py:389\u001b[39m, in \u001b[36mBaseLLM.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    378\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    380\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    385\u001b[39m     **kwargs: Any,\n\u001b[32m    386\u001b[39m ) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m    387\u001b[39m     config = ensure_config(config)\n\u001b[32m    388\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m--> \u001b[39m\u001b[32m389\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    399\u001b[39m         .generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m]\n\u001b[32m    400\u001b[39m         .text\n\u001b[32m    401\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.12/site-packages/langchain_core/language_models/llms.py:766\u001b[39m, in \u001b[36mBaseLLM.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    757\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    758\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    759\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    763\u001b[39m     **kwargs: Any,\n\u001b[32m    764\u001b[39m ) -> LLMResult:\n\u001b[32m    765\u001b[39m     prompt_strings = [p.to_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m766\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_strings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.12/site-packages/langchain_core/language_models/llms.py:973\u001b[39m, in \u001b[36mBaseLLM.generate\u001b[39m\u001b[34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    958\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m    959\u001b[39m     run_managers = [\n\u001b[32m    960\u001b[39m         callback_manager.on_llm_start(\n\u001b[32m    961\u001b[39m             \u001b[38;5;28mself\u001b[39m._serialized,\n\u001b[32m   (...)\u001b[39m\u001b[32m    971\u001b[39m         )\n\u001b[32m    972\u001b[39m     ]\n\u001b[32m--> \u001b[39m\u001b[32m973\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    978\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    979\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) > \u001b[32m0\u001b[39m:\n\u001b[32m    981\u001b[39m     run_managers = [\n\u001b[32m    982\u001b[39m         callback_managers[idx].on_llm_start(\n\u001b[32m    983\u001b[39m             \u001b[38;5;28mself\u001b[39m._serialized,\n\u001b[32m   (...)\u001b[39m\u001b[32m    990\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m missing_prompt_idxs\n\u001b[32m    991\u001b[39m     ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.12/site-packages/langchain_core/language_models/llms.py:792\u001b[39m, in \u001b[36mBaseLLM._generate_helper\u001b[39m\u001b[34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[39m\n\u001b[32m    781\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_generate_helper\u001b[39m(\n\u001b[32m    782\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    783\u001b[39m     prompts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m    788\u001b[39m     **kwargs: Any,\n\u001b[32m    789\u001b[39m ) -> LLMResult:\n\u001b[32m    790\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    791\u001b[39m         output = (\n\u001b[32m--> \u001b[39m\u001b[32m792\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m                \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[32m    796\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    799\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m    800\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._generate(prompts, stop=stop)\n\u001b[32m    801\u001b[39m         )\n\u001b[32m    802\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    803\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.12/site-packages/langchain_google_genai/llms.py:102\u001b[39m, in \u001b[36mGoogleGenerativeAI._generate\u001b[39m\u001b[34m(self, prompts, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    100\u001b[39m generations = []\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[32m--> \u001b[39m\u001b[32m102\u001b[39m     chat_result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mHumanMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    108\u001b[39m     generations.append(\n\u001b[32m    109\u001b[39m         [\n\u001b[32m    110\u001b[39m             Generation(\n\u001b[32m   (...)\u001b[39m\u001b[32m    118\u001b[39m         ]\n\u001b[32m    119\u001b[39m     )\n\u001b[32m    120\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m LLMResult(generations=generations)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.12/site-packages/langchain_google_genai/chat_models.py:1433\u001b[39m, in \u001b[36mChatGoogleGenerativeAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[39m\n\u001b[32m   1406\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_generate\u001b[39m(\n\u001b[32m   1407\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1408\u001b[39m     messages: List[BaseMessage],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1419\u001b[39m     **kwargs: Any,\n\u001b[32m   1420\u001b[39m ) -> ChatResult:\n\u001b[32m   1421\u001b[39m     request = \u001b[38;5;28mself\u001b[39m._prepare_request(\n\u001b[32m   1422\u001b[39m         messages,\n\u001b[32m   1423\u001b[39m         stop=stop,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1431\u001b[39m         **kwargs,\n\u001b[32m   1432\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1433\u001b[39m     response: GenerateContentResponse = \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1434\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1435\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1436\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_method\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1437\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdefault_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1438\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1439\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _response_to_result(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.12/site-packages/langchain_google_genai/chat_models.py:231\u001b[39m, in \u001b[36m_chat_with_retry\u001b[39m\u001b[34m(generation_method, **kwargs)\u001b[39m\n\u001b[32m    222\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    224\u001b[39m params = (\n\u001b[32m    225\u001b[39m     {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m _allowed_params_prediction_service}\n\u001b[32m    226\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (request := kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m   (...)\u001b[39m\u001b[32m    229\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m kwargs\n\u001b[32m    230\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m231\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.12/site-packages/tenacity/__init__.py:336\u001b[39m, in \u001b[36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    334\u001b[39m copy = \u001b[38;5;28mself\u001b[39m.copy()\n\u001b[32m    335\u001b[39m wrapped_f.statistics = copy.statistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m336\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.12/site-packages/tenacity/__init__.py:475\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    473\u001b[39m retry_state = RetryCallState(retry_object=\u001b[38;5;28mself\u001b[39m, fn=fn, args=args, kwargs=kwargs)\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    476\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    477\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.12/site-packages/tenacity/__init__.py:376\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    374\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m376\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.12/site-packages/tenacity/__init__.py:418\u001b[39m, in \u001b[36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    416\u001b[39m retry_exc = \u001b[38;5;28mself\u001b[39m.retry_error_cls(fut)\n\u001b[32m    417\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.reraise:\n\u001b[32m--> \u001b[39m\u001b[32m418\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfut\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexception\u001b[39;00m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.12/site-packages/tenacity/__init__.py:185\u001b[39m, in \u001b[36mRetryError.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    183\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> t.NoReturn:\n\u001b[32m    184\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.last_attempt.failed:\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlast_attempt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    186\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.12/concurrent/futures/_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.12/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.12/site-packages/tenacity/__init__.py:478\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    477\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m478\u001b[39m         result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    479\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[32m    480\u001b[39m         retry_state.set_exception(sys.exc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.12/site-packages/langchain_google_genai/chat_models.py:222\u001b[39m, in \u001b[36m_chat_with_retry.<locals>._chat_with_retry\u001b[39m\u001b[34m(**kwargs)\u001b[39m\n\u001b[32m    218\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ChatGoogleGenerativeAIError(\n\u001b[32m    219\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid argument provided to Gemini: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    220\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    221\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m222\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.12/site-packages/langchain_google_genai/chat_models.py:206\u001b[39m, in \u001b[36m_chat_with_retry.<locals>._chat_with_retry\u001b[39m\u001b[34m(**kwargs)\u001b[39m\n\u001b[32m    203\u001b[39m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_chat_with_retry\u001b[39m(**kwargs: Any) -> Any:\n\u001b[32m    205\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgeneration_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    207\u001b[39m     \u001b[38;5;66;03m# Do not retry for these errors.\u001b[39;00m\n\u001b[32m    208\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m google.api_core.exceptions.FailedPrecondition \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:868\u001b[39m, in \u001b[36mGenerativeServiceClient.generate_content\u001b[39m\u001b[34m(self, request, model, contents, retry, timeout, metadata)\u001b[39m\n\u001b[32m    865\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_universe_domain()\n\u001b[32m    867\u001b[39m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m868\u001b[39m response = \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    869\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    870\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    871\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[32m    876\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py:131\u001b[39m, in \u001b[36m_GapicCallable.__call__\u001b[39m\u001b[34m(self, timeout, retry, compression, *args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    129\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mcompression\u001b[39m\u001b[33m\"\u001b[39m] = compression\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py:293\u001b[39m, in \u001b[36mRetry.__call__.<locals>.retry_wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    289\u001b[39m target = functools.partial(func, *args, **kwargs)\n\u001b[32m    290\u001b[39m sleep_generator = exponential_sleep_generator(\n\u001b[32m    291\u001b[39m     \u001b[38;5;28mself\u001b[39m._initial, \u001b[38;5;28mself\u001b[39m._maximum, multiplier=\u001b[38;5;28mself\u001b[39m._multiplier\n\u001b[32m    292\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py:153\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    149\u001b[39m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[32m    150\u001b[39m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    152\u001b[39m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m     \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m        \u001b[49m\u001b[43msleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[32m    164\u001b[39m     time.sleep(sleep)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.12/site-packages/google/api_core/retry/retry_base.py:212\u001b[39m, in \u001b[36m_retry_error_helper\u001b[39m\u001b[34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[39m\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[32m    207\u001b[39m     final_exc, source_exc = exc_factory_fn(\n\u001b[32m    208\u001b[39m         error_list,\n\u001b[32m    209\u001b[39m         RetryFailureReason.NON_RETRYABLE_ERROR,\n\u001b[32m    210\u001b[39m         original_timeout,\n\u001b[32m    211\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msource_exc\u001b[39;00m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    214\u001b[39m     on_error_fn(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py:144\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m         result = \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    145\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m inspect.isawaitable(result):\n\u001b[32m    146\u001b[39m             warnings.warn(_ASYNC_RETRY_WARNING)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.12/site-packages/google/api_core/timeout.py:130\u001b[39m, in \u001b[36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    126\u001b[39m         remaining_timeout = \u001b[38;5;28mself\u001b[39m._timeout\n\u001b[32m    128\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m] = remaining_timeout\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.12/site-packages/google/api_core/grpc_helpers.py:78\u001b[39m, in \u001b[36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(*args, **kwargs)\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m grpc.RpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions.from_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[31mNotFound\u001b[39m: 404 models/gemini-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods."
     ]
    }
   ],
   "source": [
    "response = llm.invoke(\"Sing a ballad of LangChain.\")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c905f5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "March 15, 2023\n"
     ]
    }
   ],
   "source": [
    "a = 'Today is Tuesday, March 15, 2023'\n",
    "date_part = ', '.join(a.split(', ')[1:])  # Join and then split\n",
    "print(date_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86b00041",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'poem' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mpoem\u001b[49m.split(\u001b[33m'\u001b[39m\u001b[33m,\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m2\u001b[39m)[\u001b[32m1\u001b[39m:]\n",
      "\u001b[31mNameError\u001b[39m: name 'poem' is not defined"
     ]
    }
   ],
   "source": [
    "poem.split(',', 2)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363febaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b857a0ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi, how can I help you?'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(\"hello ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c235a80e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dear [Name],\n",
      "\n",
      "I am writing to request funding for an electronic item that would be a valuable asset to my work as a [Your job title].\n",
      "\n",
      "The item I am requesting is a [Item name], which would allow me to [What you would use the item for]. This would save me time and improve my productivity, as I would no longer need to [What you currently do without the item].\n",
      "\n",
      "I have attached a link to the item on Amazon for your reference. The total cost is [Item price].\n",
      "\n",
      "I understand that we have a limited budget, but I believe that this purchase would be a worthwhile investment. I am confident that it would pay for itself in terms of increased productivity and efficiency.\n",
      "\n",
      "Thank you for your consideration. I look forward to hearing from you soon.\n",
      "\n",
      "Sincerely,\n",
      "[Your name]\n"
     ]
    }
   ],
   "source": [
    "essay = llm(\"write email requesting fund for electronic item\")\n",
    "print(essay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "227816a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import GooglePalmEmbeddings\n",
    "from langchain.llms import GooglePalm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765695b5",
   "metadata": {},
   "source": [
    "### Now let's load data from Codebasics FAQ csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c62e35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "loader = CSVLoader(file_path='codebasics_faqs.csv', source_column=\"prompt\", encoding='cp1252')\n",
    "\n",
    "# Store the loaded data in the 'data' variable\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd45e51",
   "metadata": {},
   "source": [
    "### Hugging Face Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04a4de8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "\n",
    "# Initialize instructor embeddings using the Hugging Face model\n",
    "instructor_embeddings = HuggingFaceInstructEmbeddings(model_name=\"hkunlp/instructor-large\")\n",
    "\n",
    "e = instructor_embeddings.embed_query(\"What is your refund policy?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0762eeac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6fab6ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.043898068368434906,\n",
       " 0.007685532793402672,\n",
       " -0.009231905452907085,\n",
       " 0.02449626475572586,\n",
       " 0.033592287451028824]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e571c0d2",
   "metadata": {},
   "source": [
    "As you can see above, embedding for a sentance \"What is your refund policy\" is a list of size 768. Looking at the numbers in this list, doesn't give any intuitive understanding of what it is but just assume that these numbers are capturing the meaning of \"What is your refund policy\". If you are curious to know about embeddings, go to youtube and search \"codebasics word embeddings\" and you will find bunch of videos with simple, intuitive explanations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc80a28a",
   "metadata": {},
   "source": [
    "### Vector store using FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3c706da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# Create a FAISS instance for vector database from 'data'\n",
    "vectordb = FAISS.from_documents(documents=data,\n",
    "                                 embedding=instructor_embeddings)\n",
    "\n",
    "# Create a retriever for querying the vector database\n",
    "retriever = vectordb.as_retriever(score_threshold = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cfd58f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='prompt: Do you provide any job assistance?\\nresponse: Yes, We help you with resume and interview preparation along with that we help you in building online credibility, and based on requirements we refer candidates to potential recruiters.', metadata={'source': 'Do you provide any job assistance?', 'row': 11}),\n",
       " Document(page_content='prompt: Will this course guarantee me a job?\\nresponse: We created a much lighter version of this course on YouTube available for free (click this link) and many people gave us feedback that they were able to fetch jobs (see testimonials). Now this paid course is at least 5x better than the YouTube course which gives us ample confidence that you will be able to get a job. However, we want to be honest and do not want to make any impractical promises! Our guarantee is to prepare you for the job market by teaching the most relevant skills, knowledge & timeless principles good enough to fetch the job.', metadata={'source': 'Will this course guarantee me a job?', 'row': 33}),\n",
       " Document(page_content='prompt: Will this bootcamp guarantee me a job?\\nresponse: The courses included in this bootcamp are done by 9000+ learners and many of them have secured a job which gives us ample confidence that you will be able to get a job. However, we want to be honest and do not want to make any impractical promises! Our guarantee is to prepare you for the job market by teaching the most relevant skills, knowledge & timeless principles good enough to fetch the job.', metadata={'source': 'Will this bootcamp guarantee me a job?', 'row': 15}),\n",
       " Document(page_content='prompt: Do you provide any virtual internship?\\nresponse: Yes', metadata={'source': 'Do you provide any virtual internship?', 'row': 14})]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdocs = retriever.get_relevant_documents(\"how about job placement support?\")\n",
    "rdocs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf6b257",
   "metadata": {},
   "source": [
    "As you can see above, the retriever that was created using FAISS and hugging face embedding is now capable of pulling relavant documents from our original CSV file knowledge store. This is very powerful and it will help us further in our project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bee857",
   "metadata": {},
   "source": [
    "##### Embeddings can be created using GooglePalm too. Also for vector database you can use chromadb as well as shown below. During our experimentation, we found hugging face embeddings and FAISS to be more appropriate for our use case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a93d079d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# google_palm_embeddings = GooglePalmEmbeddings(google_api_key=api_key)\n",
    "\n",
    "# from langchain.vectorstores import Chroma\n",
    "# vectordb = Chroma.from_documents(data,\n",
    "#                            embedding=google_palm_embeddings,\n",
    "#                            persist_directory='./chromadb')\n",
    "# vectordb.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f3d927",
   "metadata": {},
   "source": [
    "### Create RetrievalQA chain along with prompt template 🚀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d4842c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"Given the following context and a question, generate an answer based on this context only.\n",
    "In the answer try to provide as much text as possible from \"response\" section in the source document context without making much changes.\n",
    "If the answer is not found in the context, kindly state \"I don't know.\" Don't try to make up an answer.\n",
    "\n",
    "CONTEXT: {context}\n",
    "\n",
    "QUESTION: {question}\"\"\"\n",
    "\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "chain_type_kwargs = {\"prompt\": PROMPT}\n",
    "\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "chain = RetrievalQA.from_chain_type(llm=llm,\n",
    "                            chain_type=\"stuff\",\n",
    "                            retriever=retriever,\n",
    "                            input_key=\"query\",\n",
    "                            return_source_documents=True,\n",
    "                            chain_type_kwargs=chain_type_kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152a4cf8",
   "metadata": {},
   "source": [
    "### We are all set 👍🏼 Let's ask some questions now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90166e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Do you provide job assistance and also do you provide job gurantee',\n",
       " 'result': 'Yes, We help you with resume and interview preparation along with that we help you in building online credibility, and based on requirements we refer candidates to potential recruiters. The courses included in this bootcamp are done by 9000+ learners and many of them have secured a job which gives us ample confidence that you will be able to get a job. However, we want to be honest and do not want to make any impractical promises! Our guarantee is to prepare you for the job market by teaching the most relevant skills, knowledge & timeless principles good enough to fetch the job.',\n",
       " 'source_documents': [Document(page_content='prompt: Do you provide any job assistance?\\nresponse: Yes, We help you with resume and interview preparation along with that we help you in building online credibility, and based on requirements we refer candidates to potential recruiters.', metadata={'source': 'Do you provide any job assistance?', 'row': 11}),\n",
       "  Document(page_content='prompt: Will this bootcamp guarantee me a job?\\nresponse: The courses included in this bootcamp are done by 9000+ learners and many of them have secured a job which gives us ample confidence that you will be able to get a job. However, we want to be honest and do not want to make any impractical promises! Our guarantee is to prepare you for the job market by teaching the most relevant skills, knowledge & timeless principles good enough to fetch the job.', metadata={'source': 'Will this bootcamp guarantee me a job?', 'row': 15}),\n",
       "  Document(page_content='prompt: Will this course guarantee me a job?\\nresponse: We created a much lighter version of this course on YouTube available for free (click this link) and many people gave us feedback that they were able to fetch jobs (see testimonials). Now this paid course is at least 5x better than the YouTube course which gives us ample confidence that you will be able to get a job. However, we want to be honest and do not want to make any impractical promises! Our guarantee is to prepare you for the job market by teaching the most relevant skills, knowledge & timeless principles good enough to fetch the job.', metadata={'source': 'Will this course guarantee me a job?', 'row': 33}),\n",
       "  Document(page_content='prompt: Do you provide any virtual internship?\\nresponse: Yes', metadata={'source': 'Do you provide any virtual internship?', 'row': 14})]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain('Do you provide job assistance and also do you provide job gurantee')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a4e3e4",
   "metadata": {},
   "source": [
    "**As you can see above, the answer of question comes from two different FAQs within our csv file and it is able to pull those questions and merge them nicely**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82dce73e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Do you guys provide internship and also do you offer EMI payments?',\n",
       " 'result': \"Yes, we provide virtual internship and we don't offer EMI payments.\",\n",
       " 'source_documents': [Document(page_content='prompt: Do you provide any virtual internship?\\nresponse: Yes', metadata={'source': 'Do you provide any virtual internship?', 'row': 14}),\n",
       "  Document(page_content='prompt: Do we have an EMI option?\\nresponse: No', metadata={'source': 'Do we have an EMI option?', 'row': 13}),\n",
       "  Document(page_content='prompt: Do you provide any job assistance?\\nresponse: Yes, We help you with resume and interview preparation along with that we help you in building online credibility, and based on requirements we refer candidates to potential recruiters.', metadata={'source': 'Do you provide any job assistance?', 'row': 11}),\n",
       "  Document(page_content='prompt: How can I contact the instructors for any doubts/support?\\nresponse: We have created every lecture with a motive to explain everything in an easy-to-understand manner. While working on these lectures you could make mistakes in steps or have some doubts. You need to commit yourself to hold patience, make efforts & diagnose the errors yourself by googling in order to become truly job ready. For any questions, that Google cannot answer or if you hit a wall - we got you covered! You can join our active discord community. which is a dedicated platform to discuss & clear your doubts with fellow learners & mentors.', metadata={'source': 'How can I contact the instructors for any doubts/support?', 'row': 5})]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain(\"Do you guys provide internship and also do you offer EMI payments?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48970302",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'do you have javascript course?',\n",
       " 'result': 'Yes, we have a 10-week JavaScript course that will teach you everything you need to know to become a JavaScript developer.',\n",
       " 'source_documents': [Document(page_content='prompt: Do you have Flask course?\\nresponse: No', metadata={'source': 'Do you have Flask course?', 'row': 82}),\n",
       "  Document(page_content='prompt: I have never done programming and belong to a non-technical background. Can I take this course?\\nresponse: Yes, this is the perfect course for anyone who has never done coding and wants to build a career in the IT/Data Analytics industry or just wants to perform better in their current job or business using data.', metadata={'source': 'I have never done programming and belong to a non-technical background. Can I take this course?', 'row': 24}),\n",
       "  Document(page_content='prompt: Do you have Django course?\\nresponse: No', metadata={'source': 'Do you have Django course?', 'row': 81}),\n",
       "  Document(page_content='prompt: I have never done programming in my life. Can I take this bootcamp?\\nresponse: Yes, this is the perfect bootcamp for anyone who has never done coding and wants to build a career in the IT/Data Analytics industry or just wants to perform better in your current job or business using data.', metadata={'source': 'I have never done programming in my life. Can I take this bootcamp?', 'row': 0})]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain(\"do you have javascript course?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c17dc6c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Do you have plans to launch blockchain course in future?',\n",
       " 'result': \"I don't know.\",\n",
       " 'source_documents': [Document(page_content='prompt: Will the course be upgraded when there are new features in Power BI?\\nresponse: Yes, the course will be upgraded periodically based on the new features in Power BI, and learners who have already bought this course will have free access to the upgrades.', metadata={'source': 'Will the course be upgraded when there are new features in Power BI?', 'row': 27}),\n",
       "  Document(page_content='prompt: What business concepts and domains are covered in this course?\\nresponse: We have covered the core functions such as Sales, Marketing, Finance, and Supply Chain with their fundamentals related to this course. The domain you will learn in this course is consumer goods which is projected to have more openings and high data analytics requirements at least until 2030.', metadata={'source': 'What business concepts and domains are covered in this course?', 'row': 32}),\n",
       "  Document(page_content='prompt: How can I contact the instructors for any doubts/support?\\nresponse: We have created every lecture with a motive to explain everything in an easy-to-understand manner. While working on these lectures you could make mistakes in steps or have some doubts. You need to commit yourself to hold patience, make efforts & diagnose the errors yourself by googling in order to become truly job ready. For any questions, that Google cannot answer or if you hit a wall - we got you covered! You can join our active discord community. which is a dedicated platform to discuss & clear your doubts with fellow learners & mentors.', metadata={'source': 'How can I contact the instructors for any doubts/support?', 'row': 5}),\n",
       "  Document(page_content='prompt: What is different in this course compared to hundreds of courses on the internet and free tutorials on YouTube?\\nresponse: Most of the courses available on the internet teach you how to build x & y without any business context and do not prepare you for real business world problem-solving. This course is rather an experience in which you will learn Excel by solving real-life use cases in an imaginary company called AtliQ Hardware. The tutorials are very easy to understand and also have a lot of fun elements into them so that you don’t get bored ??', metadata={'source': 'What is different in this course compared to hundreds of courses on the internet and free tutorials on YouTube?', 'row': 18})]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain(\"Do you have plans to launch blockchain course in future?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c35c2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.google_palm.generate_with_retry.<locals>._generate_with_retry in 2.0 seconds as it raised InternalServerError: 500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting.\n",
      "Retrying langchain.llms.google_palm.generate_with_retry.<locals>._generate_with_retry in 4.0 seconds as it raised InternalServerError: 500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'should I learn power bi or tableau?',\n",
       " 'result': 'This is a contextual question. If you are talking about a pure visualization tool Tableau is slightly better. Data connectors, modeling and transformation features are available in both. However, factually speaking Power BI is cheaper and offers tighter integration with the Microsoft environment. Since most companies use excel & Microsoft tools they start with Power BI or move towards Power BI for seamless integration with other Microsoft tools (called as Power platform). This makes the job openings grow at a much higher rate on Power BI and Power Platform. Also, Power BI has been leading the Gartner’s magic quadrant in BI for the last few years as the industry leader.',\n",
       " 'source_documents': [Document(page_content='prompt: Power BI or Tableau which one is better?\\nresponse: This is a contextual question. If you are talking about a pure visualization tool Tableau is slightly better. Data connectors, modeling and transformation features are available in both. However, factually speaking Power BI is cheaper and offers tighter integration with the Microsoft environment. Since most companies use excel & Microsoft tools they start with Power BI or move towards Power BI for seamless integration with other Microsoft tools (called as Power platform). This makes the job openings grow at a much higher rate on Power BI and Power Platform. Also, Power BI has been leading the Gartner’s magic quadrant in BI for the last few years as the industry leader.', metadata={'source': '\\nPower BI or Tableau which one is better?', 'row': 29}),\n",
       "  Document(page_content='prompt: power bi course\\nresponse: Get Job Ready: Power BI Data Analytics for All Levels This practical beginnerÕs course lets you learn Power BI from scratch, preparing you for the data analyst, business analyst, or Power BI developer job market. The course provides an end-to-end Power BI. follow the link: \"https://codebasics.io/courses/power-bi-data-analysis-with-end-to-end-project\"', metadata={'source': 'power bi course', 'row': 80}),\n",
       "  Document(page_content='prompt: What is different in this course from thousands of other Power BI courses available online?\\nresponse: Most of the courses available on the internet teach you how to build x & y without any business context and do not prepare you for the real business world. This course is rather an experience in which you will learn how to use Power BI & other non-technical skills to solve a real-life business problem using analytics. Here you focus on solving a business problem and in that process learn how Power BI can be used as a tool. This is how you will do the work when you start working as a data analyst/ Business analyst/ Power BI developer in the industry. This course will prepare you for not just fetching the job but, shine in it & grow further.', metadata={'source': 'What is different in this course from thousands of other Power BI courses available online?', 'row': 36}),\n",
       "  Document(page_content='prompt: power bi slicer?\\nresponse: Slicers are an integral part of a business report generated using Power BI. The functionality of a slicer can be considered similar to that of a filter, but, unlike a filter, a Slicer can display a visual representation of all values and users will be provided with the option to select from the available values in the slicerÕs drop-down menu.', metadata={'source': 'power bi slicer?', 'row': 84})]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain(\"should I learn power bi or tableau?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a054c5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.google_palm.generate_with_retry.<locals>._generate_with_retry in 2.0 seconds as it raised InternalServerError: 500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting.\n",
      "Retrying langchain.llms.google_palm.generate_with_retry.<locals>._generate_with_retry in 4.0 seconds as it raised InternalServerError: 500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting.\n",
      "Retrying langchain.llms.google_palm.generate_with_retry.<locals>._generate_with_retry in 8.0 seconds as it raised InternalServerError: 500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': \"I've a MAC computer. Can I use powerbi on it?\",\n",
       " 'result': 'response: Hi\\n\\nPower BI desktop works only in Windows OS. Please look into the system requirements section on this page. However, you can use a virtual machine to install and work with Power BI in other Operating systems.',\n",
       " 'source_documents': [Document(page_content='prompt: How can I use PowerBI on my Mac system?\\nresponse: Hi\\n\\nYou can use VirtualBox to create a virtual machine and install Windows on it. This will allow you to run Power BI and Excel on your Mac.\\n\\nIf you\\'re not familiar with setting up a virtual machine, there are many resources available on YouTube that can guide you through the process. Simply search for \"installing virtual machines\" and you\\'ll find plenty of helpful videos.\\n\\nBest of luck with your studies!', metadata={'source': 'How can I use PowerBI on my Mac system?', 'row': 44}),\n",
       "  Document(page_content='prompt: Does Power BI work in Mac OS/Ubuntu?\\nresponse: Power BI desktop works only in Windows OS. Please look into the system requirements section on this page. However, you can use a virtual machine to install and work with Power BI in other Operating systems.', metadata={'source': 'Does Power BI work in Mac OS/Ubuntu?', 'row': 31}),\n",
       "  Document(page_content='prompt: i am unable to import data from mysql in power bi ,connector issue is coming continuously i have done all steps according to connector pdf still its not resolving please guide\\nresponse: Please refer to this thread: https://discord.com/channels/1090613684163850280/1107992760105054238/1107993007606730802', metadata={'source': 'i am unable to import data from mysql in power bi ,connector issue is coming continuously i have done all steps according to connector pdf still its not resolving please guide', 'row': 54}),\n",
       "  Document(page_content='prompt: Is this bootcamp enough for me in Microsoft Power BI and\\n Excel certifications?\\nresponse: Yes, this bootcamp will certainly help because we cover the majority of the skills measured in these exams. However, please be informed that this course focuses on Job ready aspects and not on all aspects required to clear the exams. In addition to this course, you might need to visit the official learning material designed by Microsoft which is available for free on their website.', metadata={'source': 'Is this bootcamp enough for me in Microsoft Power BI and\\n Excel certifications?', 'row': 12})]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain(\"I've a MAC computer. Can I use powerbi on it?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "89fa5d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': \"I don't see power pivot. how can I enable it?\",\n",
       " 'result': 'Follow this thread for instructions - https://support.microsoft.com/en-us/office/start-the-power-pivot-add-in-for-excel-a891a66d-36e3-43fc-81e8-fc4798f39ea8\\nIf it doesn\\'t show in the ribbon then go to \"insert\" tab. You will be able to see pivot table option there.',\n",
       " 'source_documents': [Document(page_content='prompt: How to install power pivot if its not available in system?\\nresponse: Follow this thread for instructions - https://support.microsoft.com/en-us/office/start-the-power-pivot-add-in-for-excel-a891a66d-36e3-43fc-81e8-fc4798f39ea8\\nIf it doesn\\'t show in the ribbon then go to \"insert\" tab. You will be able to see pivot table option there.', metadata={'source': 'How to install power pivot if its not available in system?', 'row': 38}),\n",
       "  Document(page_content='prompt: How do I enable Power Pivot before using it for the first time ?\\nresponse: Follow the process in the link : \\n\\nhttps://drive.google.com/file/d/1-mO-v52h-YTY1s-v30liBJPu6Yj4OUxb/view?usp=share_link', metadata={'source': 'How do I enable Power Pivot before using it for the first time ?', 'row': 74}),\n",
       "  Document(page_content='prompt: why row and value option is not showing for the visual in PowerBI , any setting need to be change, please let me know?\\nresponse: You have selected Table Visual instead of Matrix. That is why you are seeing a different interface.', metadata={'source': 'why row and value option is not showing for the visual in PowerBI , any setting need to be change, please let me know?', 'row': 46}),\n",
       "  Document(page_content=\"prompt: The fact_sales_monthly table seems to be missing. Could you please provide information about why it is not available?\\nresponse: Delete the existing databases in MySQL workbench and re-import again. After this go to 'Home' tab in Power Query and click on Refresh button and see if it works any.\", metadata={'source': 'The fact_sales_monthly table seems to be missing. Could you please provide information about why it is not available?', 'row': 61})]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain(\"I don't see power pivot. how can I enable it?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c6539e58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What is the price of your machine learning course?',\n",
       " 'result': \"I don't know.\",\n",
       " 'source_documents': [Document(page_content='prompt: I’m not sure if this course is good enough for me to invest some money. What can I do?\\nresponse: Don’t worry. Many videos in this course are free so watch them to get an idea of the quality of teaching. Dhaval Patel (the course instructor) runs a popular data science YouTube channel called Codebasics. On that, you can watch his videos and read comments to get an idea of his teaching style', metadata={'source': 'I’m not sure if this course is good enough for me to invest some money. What can I do?', 'row': 20}),\n",
       "  Document(page_content='prompt: Will the course be upgraded when there are new features in Power BI?\\nresponse: Yes, the course will be upgraded periodically based on the new features in Power BI, and learners who have already bought this course will have free access to the upgrades.', metadata={'source': 'Will the course be upgraded when there are new features in Power BI?', 'row': 27}),\n",
       "  Document(page_content='prompt: What is different in this course compared to hundreds of courses on the internet and free tutorials on YouTube?\\nresponse: Most of the courses available on the internet teach you how to build x & y without any business context and do not prepare you for real business world problem-solving. This course is rather an experience in which you will learn Excel by solving real-life use cases in an imaginary company called AtliQ Hardware. The tutorials are very easy to understand and also have a lot of fun elements into them so that you don’t get bored ??', metadata={'source': 'What is different in this course compared to hundreds of courses on the internet and free tutorials on YouTube?', 'row': 18}),\n",
       "  Document(page_content='prompt: What is different in this course from thousands of other Power BI courses available online?\\nresponse: Most of the courses available on the internet teach you how to build x & y without any business context and do not prepare you for the real business world. This course is rather an experience in which you will learn how to use Power BI & other non-technical skills to solve a real-life business problem using analytics. Here you focus on solving a business problem and in that process learn how Power BI can be used as a tool. This is how you will do the work when you start working as a data analyst/ Business analyst/ Power BI developer in the industry. This course will prepare you for not just fetching the job but, shine in it & grow further.', metadata={'source': 'What is different in this course from thousands of other Power BI courses available online?', 'row': 36})]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain(\"What is the price of your machine learning course?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
